{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from os.path import join as oj\n",
    "out_dir = '../../results/nlp'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at smth with attention..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertTokenizer, BertForMaskedLM, BertForSequenceClassification, BertConfig\n",
    "from util import *\n",
    "device = 'cpu'\n",
    "\n",
    "default = 'bert-base-uncased'\n",
    "mdir = '/scratch/users/vision/chandan/pacmed/glue/SST-2-3epoch' # '/scratch/users/vision/chandan/pacmed/glue/SST-2-middle/'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(mdir)\n",
    "clf = BertForSequenceClassification.from_pretrained(mdir).eval().to(device)\n",
    "masked_predictor = BertForMaskedLM.from_pretrained(default).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'good movie'\n",
    "with torch.no_grad():\n",
    "    print('encoded', tokenizer.convert_ids_to_tokens(tokenizer.encode(s)))\n",
    "    input_ids = torch.tensor(tokenizer.encode(s), device=device).unsqueeze(0)  # Batch size 1\n",
    "    pred = clf(input_ids)[0].detach().cpu().softmax(dim=1).numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrated gradients\n",
    "def integrated_gradients(inputs, model, target_label_idx, predict_and_gradients, baseline, steps=50, cuda=False):\n",
    "    if baseline is None:\n",
    "        baseline = 0 * inputs \n",
    "    # scale inputs and compute gradients\n",
    "    scaled_inputs = [baseline + (float(i) / steps) * (inputs - baseline) for i in range(0, steps + 1)]\n",
    "    grads, _ = predict_and_gradients(scaled_inputs, model, target_label_idx, cuda)\n",
    "    avg_grads = np.average(grads[:-1], axis=0)\n",
    "    avg_grads = np.transpose(avg_grads, (1, 2, 0))\n",
    "    integrated_grad = (inputs - baseline) * avg_grads\n",
    "    return integrated_grad\n",
    "\n",
    "def predict_and_gradients(inputs, model, target_label_idx, cuda=False):\n",
    "    # do the pre-processing\n",
    "    predict_idx = None\n",
    "    gradients = []\n",
    "    print('inputs', inputs)\n",
    "    for inp in inputs:\n",
    "        # inp = pre_processing(input, cuda)\n",
    "        output = model(inp)[0]\n",
    "        output = F.softmax(output, dim=1)\n",
    "        if target_label_idx is None:\n",
    "            target_label_idx = torch.argmax(output, 1).item()\n",
    "        index = np.ones((output.size()[0], 1)) * target_label_idx\n",
    "        index = torch.tensor(index, dtype=torch.int64)\n",
    "        if cuda:\n",
    "            index = index.cuda()\n",
    "        output = output.gather(1, index)\n",
    "        \n",
    "        # clear grad\n",
    "        model.zero_grad()\n",
    "        output.backward()\n",
    "        print('inp', inp)\n",
    "        print('inp.grad', inp.grad)\n",
    "        gradient = inp.grad.detach().cpu().numpy()[0]\n",
    "        gradients.append(gradient)\n",
    "        \n",
    "    gradients = np.array(gradients)\n",
    "    return gradients, target_label_idx\n",
    "\n",
    "integrated_gradients(input_ids, clf, 1, predict_and_gradients, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at smth with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BertForSequenceClassification.from_pretrained(mdir, output_attentions=True).eval().to(device)\n",
    "\n",
    "s = 'good movie'\n",
    "with torch.no_grad():\n",
    "    # print('encoded', tokenizer.convert_ids_to_tokens(tokenizer.encode(s)))\n",
    "    input_ids = torch.tensor(tokenizer.encode(s), device=device).unsqueeze(0)  # Batch size 1\n",
    "    pred = clf(input_ids)#[0].detach().cpu().softmax(dim=1).numpy().flatten()\n",
    "    all_attentions = pred[1]\n",
    "    pred = pred[0].detach().cpu().softmax(dim=1).numpy().flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
