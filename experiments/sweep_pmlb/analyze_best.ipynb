{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from os.path import join as oj\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 132.77it/s]\n",
      "100%|██████████| 94/94 [00:00<00:00, 170.09it/s]\n",
      "100%|██████████| 94/94 [00:00<00:00, 156.71it/s]\n"
     ]
    }
   ],
   "source": [
    "results_dir = '/accounts/projects/vision/chandan/class-weight-uncertainty/results/pmlb'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "rs = []\n",
    "for name in ['logistic', 'mlp2', 'gb']:\n",
    "    out_dir = '/scratch/users/vision/chandan/pacmed/no_flips/' + name\n",
    "    fnames = sorted([fname for fname in os.listdir(out_dir)])\n",
    "    results_list = [pd.Series(pkl.load(open(oj(out_dir, fname), \n",
    "                                            \"rb\"))) for fname in tqdm(fnames)]\n",
    "    rs.append(pd.concat(results_list, axis=1).T.infer_objects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note - cw is class-weight an pe is predictive-entropy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at best dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rs)):\n",
    "    r = deepcopy(rs[i])\n",
    "    r['auc_auc_diff'] = r.cw_auc_auc_test - r.pe_auc_auc_test\n",
    "    r['calibration_diff'] = r.cw_calibration_rmse_test - r.pe_calibration_rmse_test\n",
    "    rs[i] = r.sort_values(by='auc_auc_diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rs:\n",
    "    print(r[['dset_name', 'auc_auc_diff']].head(n=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pick best common dsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_names 10 ['tokyo1', 'churn', 'german', 'dis', 'clean2', 'coil2000', 'Hill_Valley_with_noise', 'hypothyroid', 'diabetes', 'agaricus-lepiota']\n"
     ]
    }
   ],
   "source": [
    "s0 = set(rs[0]['dset_name'][:15])\n",
    "s1 = set(rs[1]['dset_name'][:15])\n",
    "s2 = set(rs[2]['dset_name'][:15])\n",
    "\n",
    "common_names = list(s0 & s1 & s2)\n",
    "common_names += ['clean2', 'coil2000', 'Hill_Valley_with_noise', \n",
    "                 'hypothyroid', 'diabetes', 'agaricus-lepiota']\n",
    "print('common_names', len(common_names), common_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    rs[i] = rs[i][rs[i].dset_name.isin(common_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rs[0].merge(rs[1], how='outer', on='dset_name', \n",
    "                      suffixes=('', '_y'))\n",
    "results = pd.merge(results, rs[2], how='outer', on='dset_name',\n",
    "                   suffixes=('_x', '_z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dset_name', 'seed_x', 'class_weight_x', 'model_type_x', 'flip_frac_x',\n",
       "       'out_dir_x', 'pid_x', 'cw_flipped_diff_train_x',\n",
       "       'cw_flipped_diff_p_train_x', 'cw_loss_percentages_train_x',\n",
       "       ...\n",
       "       'pe_loss_auc_test_z', 'pe_auc_percentages_test_z',\n",
       "       'pe_auc_performances_test_z', 'pe_auc_auc_test_z',\n",
       "       'pe_calibration_pred_test_z', 'pe_calibration_true_test_z',\n",
       "       'pe_calibration_rmse_test_z', 'pe_ranks_test_z', 'auc_auc_diff_z',\n",
       "       'calibration_diff_z'],\n",
       "      dtype='object', length=169)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76.181632\n",
       "1    53.375482\n",
       "2    42.871320\n",
       "3    71.465215\n",
       "4    48.399229\n",
       "5    65.662951\n",
       "6    58.796164\n",
       "7    94.412386\n",
       "8    57.660494\n",
       "9    29.730631\n",
       "Name: pe_auc_auc_test_x, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pe_auc_auc_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l c c c c c c}\n",
      "& \\multicolumn{2}{c}{Logistic Regression} &\t \\multicolumn{2}{c}{2-layer multilayer perceptron} &\t \\multicolumn{2}{c}{Gradient Boosting}\\\\\n",
      "Dataset\t&\tClass-weight &\tBaseline &\tClass-weight &\tBaseline &\tClass-weight &\tBaseline\\\\\n",
      "\\hline\n",
      "Hill\\_Valley\\_with\\_noise\t&\t74.82\t&\t71.47 \t&\t\\textbf{64.38 } \t&\t54.16 \t&\t45.42\t&\t45.23\\\\\n",
      "agaricus-lepiota\t&\t94.42\t&\t94.41 \t&\t96.76\t&\t96.76 \t&\t\\textbf{96.76 } \t&\t67.70\\\\\n",
      "churn\t&\t\\textbf{61.62 } \t&\t53.38 \t&\t\\textbf{76.01 } \t&\t65.20 \t&\t86.62\t&\t81.82\\\\\n",
      "clean2\t&\t\\textbf{96.00 } \t&\t76.18 \t&\t\\textbf{93.58 } \t&\t36.00 \t&\t15.88\t&\t17.15\\\\\n",
      "coil2000\t&\t57.36\t&\t57.66 \t&\t55.11\t&\t52.58 \t&\t\\textbf{74.46 } \t&\t64.32\\\\\n",
      "diabetes\t&\t59.75\t&\t58.80 \t&\t51.60\t&\t49.57 \t&\t56.71\t&\t57.62\\\\\n",
      "dis\t&\t48.96\t&\t42.87 \t&\t\\textbf{70.42 } \t&\t37.65 \t&\t\\textbf{50.09 } \t&\t41.88\\\\\n",
      "german\t&\t51.11\t&\t48.40 \t&\t\\textbf{50.61 } \t&\t28.45 \t&\t59.98\t&\t52.50\\\\\n",
      "hypothyroid\t&\t26.30\t&\t29.73 \t&\t52.97\t&\t57.60 \t&\t\\textbf{61.79 } \t&\t45.26\\\\\n",
      "tokyo1\t&\t67.55\t&\t65.66 \t&\t68.39\t&\t65.65 \t&\t\\textbf{71.87 } \t&\t57.41\\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print('\\\\begin{tabular}{l c c c c c c}')\n",
    "print('& \\\\multicolumn{2}{c}{Logistic Regression} &\\t \\\\multicolumn{2}{c}{2-layer multilayer perceptron} &\\t \\\\multicolumn{2}{c}{Gradient Boosting}\\\\\\\\')\n",
    "print('Dataset\t&\tClass-weight &\tBaseline &\tClass-weight &\tBaseline &\tClass-weight &\tBaseline\\\\\\\\')\n",
    "print('\\hline')\n",
    "vals = [] \n",
    "thresh = 8\n",
    "bf = '\\\\textbf{'\n",
    "for name in sorted(common_names):\n",
    "    row = results[results.dset_name == name].iloc[0]\n",
    "    name = row.dset_name.replace(\"_\", \"\\_\")\n",
    "    s = f'{name}\\t&'\n",
    "    if row.cw_auc_auc_test_x > row.pe_auc_auc_test_x + thresh:\n",
    "        s += f'\\t{bf}{row.cw_auc_auc_test_x:0.2f} }} \\t&\\t{row.pe_auc_auc_test_x:0.2f} \\t&'\n",
    "    else:\n",
    "        s += f'\\t{row.cw_auc_auc_test_x:0.2f}\\t&\\t{row.pe_auc_auc_test_x:0.2f} \\t&'\n",
    "        \n",
    "    if row.cw_auc_auc_test_y > row.pe_auc_auc_test_y + thresh:\n",
    "        s += f'\\t{bf}{row.cw_auc_auc_test_y:0.2f} }} \\t&\\t{row.pe_auc_auc_test_y:0.2f} \\t&'\n",
    "    else:\n",
    "        s += f'\\t{row.cw_auc_auc_test_y:0.2f}\\t&\\t{row.pe_auc_auc_test_y:0.2f} \\t&'\n",
    "        \n",
    "    if row.cw_auc_auc_test_z > row.pe_auc_auc_test_z + thresh:\n",
    "        s += f'\\t{bf}{row.cw_auc_auc_test_z:0.2f} }} \\t&\\t{row.pe_auc_auc_test_z:0.2f}\\\\\\\\'\n",
    "    else:\n",
    "        s += f'\\t{row.cw_auc_auc_test_z:0.2f}\\t&\\t{row.pe_auc_auc_test_z:0.2f}\\\\\\\\'\n",
    "    print(s)    \n",
    "print('\\end{tabular}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
